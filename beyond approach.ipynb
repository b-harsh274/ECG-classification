{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbc77266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wfdb\n",
    "import ast\n",
    "\n",
    "def load_raw_data(df, sampling_rate):\n",
    "    if sampling_rate == 100:\n",
    "        data = [wfdb.rdsamp(f) for f in df.filename_lr]\n",
    "    else:\n",
    "        data = [wfdb.rdsamp(f) for f in df.filename_hr]\n",
    "    data = np.array([signal for signal, meta in data])\n",
    "    return data\n",
    "\n",
    "sampling_rate=100\n",
    "\n",
    "# load and convert annotation data\n",
    "df = pd.read_csv('ptbxl_database.csv', index_col='ecg_id')\n",
    "df.scp_codes = df.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# Load raw signal data\n",
    "Signals = load_raw_data(df, sampling_rate)\n",
    "\n",
    "# Load scp_statements.csv for diagnostic aggregation\n",
    "agg_df = pd.read_csv('scp_statements.csv', index_col=0)\n",
    "agg_df = agg_df[agg_df.diagnostic == 1]\n",
    "\n",
    "def aggregate_diagnostic(y_dic):\n",
    "    tmp = []\n",
    "    for key in y_dic.keys():\n",
    "        if key in agg_df.index:\n",
    "            tmp.append(agg_df.loc[key].diagnostic_class)\n",
    "    return list(set(tmp))\n",
    "\n",
    "# Apply diagnostic superclass\n",
    "df.reset_index(inplace=True)\n",
    "Labels = df.scp_codes.apply(aggregate_diagnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f87567df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "Labels.dropna(inplace = True)\n",
    "# Drop NaN values and get unique labels\n",
    "unique_labels = np.unique(np.concatenate(Labels))\n",
    "\n",
    "# Create a dictionary to map labels to one-hot vectors\n",
    "label_to_onehot = {}\n",
    "for i, label in enumerate(unique_labels):\n",
    "    onehot = [1 if j == i else 0 for j in range(len(unique_labels))]\n",
    "    label_to_onehot[label] = onehot\n",
    "\n",
    "# Create the one-hot encoded version\n",
    "Y = []\n",
    "\n",
    "for element in Labels:\n",
    "    if element:\n",
    "        onehot_sum = np.sum([label_to_onehot[label] for label in element], axis=0)\n",
    "        Y.append(onehot_sum)\n",
    "    else:\n",
    "        Y.append(np.zeros(len(unique_labels)))\n",
    "\n",
    "Y = np.stack(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0bce7407",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 0.])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[14255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "73978da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([]), list(['CD']), list(['CD', 'HYP']),\n",
       "       list(['CD', 'HYP', 'MI', 'NORM']), list(['CD', 'HYP', 'NORM']),\n",
       "       list(['CD', 'MI']), list(['CD', 'MI', 'HYP']),\n",
       "       list(['CD', 'NORM']), list(['CD', 'STTC']),\n",
       "       list(['CD', 'STTC', 'HYP']), list(['CD', 'STTC', 'MI']),\n",
       "       list(['CD', 'STTC', 'MI', 'HYP']), list(['CD', 'STTC', 'NORM']),\n",
       "       list(['HYP']), list(['HYP', 'NORM']), list(['MI']),\n",
       "       list(['MI', 'CD']), list(['MI', 'HYP']), list(['MI', 'HYP', 'CD']),\n",
       "       list(['MI', 'STTC']), list(['MI', 'STTC', 'CD']),\n",
       "       list(['MI', 'STTC', 'HYP']), list(['MI', 'STTC', 'HYP', 'CD']),\n",
       "       list(['NORM']), list(['STTC']), list(['STTC', 'HYP']),\n",
       "       list(['STTC', 'NORM'])], dtype=object)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8ddf394d",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices=[]\n",
    "for i in range(len(Labels)):\n",
    "    if Labels[i] == list(['CD', 'HYP', 'MI', 'NORM']):\n",
    "        indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cdb4411f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14255]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e419d0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(Signals, Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4dd6ae15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom metric\n",
    "def my_metric(ytrue,ypred):\n",
    "    temp = np.argsort(ypred)[-1:][0]\n",
    "    for i in range(len(ypred)):\n",
    "        ypred[i] = 0\n",
    "    ypred[temp] = 1\n",
    "    true_1 = list(np.where(ytrue)[0])\n",
    "    pred_1 = list(np.where(ypred)[0])\n",
    "    false_1 = list(np.where([i-1 for i in ytrue])[0])\n",
    "    count = 0\n",
    "    for i in pred_1:\n",
    "        if i in true_1:\n",
    "            count+=1\n",
    "    val = count/len(true_1)\n",
    "    for i in false_1:\n",
    "        if ypred[i]==1:\n",
    "            val = 0\n",
    "            break\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "26eb1bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "def train(model, dataloader, optimizer, criterion, train_data, device,scheduler):\n",
    "    print('Training')\n",
    "    model.train()\n",
    "    counter = 0\n",
    "    train_running_loss = 0.0\n",
    "    accuracy = 0\n",
    "    for i, data in tqdm(enumerate(dataloader), total=int(len(train_data)/dataloader.batch_size)):\n",
    "        counter += 1\n",
    "        data, target = data['image'].to(device), data['label'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        loss = criterion(outputs, target)\n",
    "        train_running_loss += loss.item()\n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        # update optimizer parameters\n",
    "        optimizer.step()\n",
    "        accuracy += my_metric(list(target.detach().cpu()[0].numpy()),list(outputs.detach().cpu()[0].numpy()))\n",
    "    scheduler.step()\n",
    "    train_loss = train_running_loss / counter\n",
    "    accuracy = accuracy/counter\n",
    "    return train_loss,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ad501d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdacad84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "97070dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-18 23:37:02.359835: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2024-01-18 23:37:02.359894: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-01-18 23:37:02.359917: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-01-18 23:37:02.360045: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-01-18 23:37:02.360148: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, AveragePooling1D\n",
    "\n",
    "cnn = Sequential([\n",
    "    Conv1D(256, kernel_size=4, activation='relu', input_shape=(1000,12)),\n",
    "    MaxPooling1D(pool_size=3),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Conv1D(64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=3),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "322e607f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "cnn.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bb706f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-18 23:41:02.448008: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744/1744 [==============================] - 28s 15ms/step - loss: 1169028.0000 - accuracy: 0.2365 - val_loss: 4228530.5000 - val_accuracy: 0.2391\n",
      "Epoch 2/5\n",
      "1744/1744 [==============================] - 24s 14ms/step - loss: 12367817.0000 - accuracy: 0.2464 - val_loss: 9492401.0000 - val_accuracy: 0.4137\n",
      "Epoch 3/5\n",
      "1744/1744 [==============================] - 24s 14ms/step - loss: 39950988.0000 - accuracy: 0.2457 - val_loss: 13861202.0000 - val_accuracy: 0.2348\n",
      "Epoch 4/5\n",
      "1744/1744 [==============================] - 25s 14ms/step - loss: 82425920.0000 - accuracy: 0.2411 - val_loss: 27803254.0000 - val_accuracy: 0.1542\n",
      "Epoch 5/5\n",
      "1744/1744 [==============================] - 24s 14ms/step - loss: 133159472.0000 - accuracy: 0.2398 - val_loss: 212775488.0000 - val_accuracy: 0.4137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x28e2b4bd0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split = 0.2,\n",
    "    epochs=5,\n",
    "    batch_size = 8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338a8a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
