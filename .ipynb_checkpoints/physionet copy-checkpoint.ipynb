{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e970eadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wfdb\n",
    "import ast\n",
    "\n",
    "def load_raw_data(df, sampling_rate):\n",
    "    if sampling_rate == 100:\n",
    "        data = [wfdb.rdsamp(f) for f in df.filename_lr]\n",
    "    else:\n",
    "        data = [wfdb.rdsamp(f) for f in df.filename_hr]\n",
    "    data = np.array([signal for signal, meta in data])\n",
    "    return data\n",
    "\n",
    "sampling_rate=100\n",
    "\n",
    "# load and convert annotation data\n",
    "df = pd.read_csv('ptbxl_database.csv', index_col='ecg_id')\n",
    "df.scp_codes = df.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# Load raw signal data\n",
    "Signals = load_raw_data(df, sampling_rate)\n",
    "\n",
    "# Load scp_statements.csv for diagnostic aggregation\n",
    "agg_df = pd.read_csv('scp_statements.csv', index_col=0)\n",
    "agg_df = agg_df[agg_df.diagnostic == 1]\n",
    "\n",
    "def aggregate_diagnostic(y_dic):\n",
    "    tmp = []\n",
    "    for key in y_dic.keys():\n",
    "        if key in agg_df.index:\n",
    "            tmp.append(agg_df.loc[key].diagnostic_class)\n",
    "    return list(set(tmp))\n",
    "\n",
    "# Apply diagnostic superclass\n",
    "df.reset_index(inplace=True)\n",
    "Labels = df.scp_codes.apply(aggregate_diagnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "547c259a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21799"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "34804301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([list([]), list(['CD']), list(['HYP']), list(['HYP', 'CD']),\n",
       "        list(['MI']), list(['MI', 'CD']), list(['MI', 'HYP']),\n",
       "        list(['MI', 'HYP', 'CD']), list(['MI', 'NORM', 'HYP', 'CD']),\n",
       "        list(['MI', 'STTC']), list(['MI', 'STTC', 'CD']),\n",
       "        list(['MI', 'STTC', 'HYP']), list(['MI', 'STTC', 'HYP', 'CD']),\n",
       "        list(['NORM']), list(['NORM', 'CD']), list(['NORM', 'HYP']),\n",
       "        list(['NORM', 'HYP', 'CD']), list(['NORM', 'STTC']),\n",
       "        list(['NORM', 'STTC', 'CD']), list(['STTC']), list(['STTC', 'CD']),\n",
       "        list(['STTC', 'HYP']), list(['STTC', 'HYP', 'CD'])], dtype=object),\n",
       " array([ 411, 1708,  535,  300, 2532, 1297,  183,  117,    1,  599,  223,\n",
       "         361,  156, 9069,  407,    2,    2,   28,    5, 2400,  471,  781,\n",
       "         211]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8443aa93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21799"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "22475526",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Encoders require their input argument must be uniformly strings or numbers. Got ['list']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/utils/_encode.py:171\u001b[0m, in \u001b[0;36m_unique_python\u001b[0;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 171\u001b[0m     uniques_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(values)\n\u001b[1;32m    172\u001b[0m     uniques_set, missing_values \u001b[38;5;241m=\u001b[39m _extract_missing(uniques_set)\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Y_encoded \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39mfit_transform(Labels)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:115\u001b[0m, in \u001b[0;36mLabelEncoder.fit_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit label encoder and return encoded labels.\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    Encoded labels.\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    114\u001b[0m y \u001b[38;5;241m=\u001b[39m column_or_1d(y, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_, y \u001b[38;5;241m=\u001b[39m _unique(y, return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/utils/_encode.py:42\u001b[0m, in \u001b[0;36m_unique\u001b[0;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Helper function to find unique values with support for python objects.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03mUses pure python method for object dtype, and numpy method for\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m    array. Only provided if `return_counts` is True.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unique_python(\n\u001b[1;32m     43\u001b[0m         values, return_inverse\u001b[38;5;241m=\u001b[39mreturn_inverse, return_counts\u001b[38;5;241m=\u001b[39mreturn_counts\n\u001b[1;32m     44\u001b[0m     )\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# numerical\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _unique_np(\n\u001b[1;32m     47\u001b[0m     values, return_inverse\u001b[38;5;241m=\u001b[39mreturn_inverse, return_counts\u001b[38;5;241m=\u001b[39mreturn_counts\n\u001b[1;32m     48\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/utils/_encode.py:179\u001b[0m, in \u001b[0;36m_unique_python\u001b[0;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m     types \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(t\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mtype\u001b[39m(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values))\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoders require their input argument must be uniformly \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    181\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrings or numbers. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    182\u001b[0m     )\n\u001b[1;32m    183\u001b[0m ret \u001b[38;5;241m=\u001b[39m (uniques,)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_inverse:\n",
      "\u001b[0;31mTypeError\u001b[0m: Encoders require their input argument must be uniformly strings or numbers. Got ['list']"
     ]
    }
   ],
   "source": [
    "Y_encoded = label_encoder.fit_transform(Labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9651667",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_labels = [item for sublist in Labels for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "120bacc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['CD', 'HYP', 'MI', 'NORM', 'STTC'], dtype='<U4'),\n",
       " array([4898, 2649, 5469, 9514, 5235]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(flat_labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a1d027a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['CD', 'HYP', 'MI', 'NORM', 'STTC'], dtype='<U4'),\n",
       " array([1708,  535, 2532, 9069, 2400]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c079476e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27765"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flat_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f585259f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4abda38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=[]\n",
    "x=[]\n",
    "for i in range(len(Labels)):\n",
    "    if Labels[i] == list(['CD']):\n",
    "        y.append('CD')\n",
    "        x.append(Signals[i,:,0])\n",
    "    if Labels[i] == list(['HYP']):\n",
    "        y.append('HYP')\n",
    "        x.append(Signals[i,:,0])\n",
    "    if Labels[i] == list(['NORM']):\n",
    "        y.append('NORM')\n",
    "        x.append(Signals[i,:,0])\n",
    "    if Labels[i] == list(['STTC']):\n",
    "        y.append('STTC')\n",
    "        x.append(Signals[i,:,0])\n",
    "    if Labels[i] == list(['MI']):\n",
    "        y.append('MI')\n",
    "        x.append(Signals[i,:,0])\n",
    "\n",
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b98544e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8099aa34",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 3 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m         augmented_signals\u001b[38;5;241m.\u001b[39mappend(noisy_signal)\n\u001b[1;32m     13\u001b[0m         augmented_labels\u001b[38;5;241m.\u001b[39mextend([y[index]] \u001b[38;5;241m*\u001b[39m augmentation_factor)\n\u001b[0;32m---> 15\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([x] \u001b[38;5;241m+\u001b[39m augmented_signals)\n\u001b[1;32m     16\u001b[0m Y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([y, np\u001b[38;5;241m.\u001b[39marray(augmented_labels)])\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 3 dimension(s)"
     ]
    }
   ],
   "source": [
    "augmented_signals = []\n",
    "augmented_labels = []\n",
    "\n",
    "\n",
    "for label in ['CD', 'HYP', 'MI', 'STTC']:\n",
    "    target_indices = np.where(y == label)[0]\n",
    "    augmentation_factor = (np.count_nonzero(y == 'NORM')  // np.count_nonzero(y == label)) -1\n",
    "    \n",
    "    for index in target_indices:\n",
    "        repeated_signal = np.tile(x[index], (augmentation_factor, 1, 1))\n",
    "        noisy_signal = repeated_signal + 0.01 * np.random.randn(*repeated_signal.shape)\n",
    "        augmented_signals.append(noisy_signal)\n",
    "        augmented_labels.extend([y[index]] * augmentation_factor)\n",
    "    \n",
    "X = np.concatenate([x] + augmented_signals)\n",
    "Y = np.concatenate([y, np.array(augmented_labels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00045c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "Y_encoded = label_encoder.fit_transform(Y)\n",
    "\n",
    "Y_onehot = to_categorical(Y_encoded, num_classes=5)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y_onehot, test_size=0.2, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c28a4ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train\n",
    "Y = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d859415",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-18 20:03:26.325748: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2024-01-18 20:03:26.325785: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-01-18 20:03:26.325793: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-01-18 20:03:26.326084: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-01-18 20:03:26.326298: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# CNN model\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Conv1D(128, kernel_size=3, activation='relu', input_shape=(1000, 12)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Conv1D(128, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv1D(128, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a5bd71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, AveragePooling1D\n",
    "\n",
    "cnn = Sequential([\n",
    "    Conv1D(256, kernel_size=4, activation='relu', input_shape=(1000,12)),\n",
    "    MaxPooling1D(pool_size=3),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Conv1D(64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=3),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10071498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78539, 1000, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "510ddf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "cnn.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8293d821",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/harshbalgude/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/harshbalgude/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/harshbalgude/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/harshbalgude/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/harshbalgude/miniconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/harshbalgude/miniconda3/lib/python3.11/site-packages/keras/src/engine/input_spec.py\", line 235, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_1' (type Sequential).\n    \n    Input 0 of layer \"max_pooling1d_3\" is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, None, None, 128)\n    \n    Call arguments received by layer 'sequential_1' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, None, None, None), dtype=float32)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequence\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TimeseriesGenerator\n\u001b[1;32m      3\u001b[0m generator \u001b[38;5;241m=\u001b[39m TimeseriesGenerator(X_train, y_train, length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(generator, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/k6/2sv64y2n2x30zc_wwpgjvy4h0000gn/T/__autograph_generated_filevdoo2e_d.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/harshbalgude/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/harshbalgude/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/harshbalgude/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/harshbalgude/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/harshbalgude/miniconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/harshbalgude/miniconda3/lib/python3.11/site-packages/keras/src/engine/input_spec.py\", line 235, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_1' (type Sequential).\n    \n    Input 0 of layer \"max_pooling1d_3\" is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, None, None, 128)\n    \n    Call arguments received by layer 'sequential_1' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, None, None, None), dtype=float32)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "generator = TimeseriesGenerator(X_train, y_train, length=200, batch_size=8)\n",
    "\n",
    "model.fit(generator, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b00f04c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-18 20:08:28.136246: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3278/3278 [==============================] - 51s 15ms/step - loss: 1.0108 - accuracy: 0.6358 - val_loss: 1.3413 - val_accuracy: 0.5812\n",
      "Epoch 2/5\n",
      "3278/3278 [==============================] - 47s 14ms/step - loss: 2.4853 - accuracy: 0.6279 - val_loss: 4.5528 - val_accuracy: 0.5921\n",
      "Epoch 3/5\n",
      "3278/3278 [==============================] - 46s 14ms/step - loss: 14.2313 - accuracy: 0.6001 - val_loss: 21.1200 - val_accuracy: 0.6117\n",
      "Epoch 4/5\n",
      "3278/3278 [==============================] - 46s 14ms/step - loss: 57.6290 - accuracy: 0.5987 - val_loss: 97.2159 - val_accuracy: 0.5617\n",
      "Epoch 5/5\n",
      "3278/3278 [==============================] - 45s 14ms/step - loss: 192.3063 - accuracy: 0.5828 - val_loss: 492.9402 - val_accuracy: 0.4876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x4d229d250>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split = 0.2,\n",
    "    epochs=5,\n",
    "    batch_size = 8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c47a78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "generator = TimeseriesGenerator(X_train, y_train, length=1000, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db7b0296",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 998, 128)          4736      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 499, 128)          0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 499, 128)          0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 497, 128)          49280     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 248, 128)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 248, 128)          0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 246, 128)          49280     \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPoolin  (None, 123, 128)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 123, 128)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 15744)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               4030720   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4135301 (15.77 MB)\n",
      "Trainable params: 4135301 (15.77 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ea38c607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9793"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6710b4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32772"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "30ee7d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_1d_resnet18(input_shape, num_classes):\n",
    "    input_tensor = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Initial Convolution\n",
    "    x = layers.Conv1D(64, kernel_size=7, strides=2, padding='same', activation='relu')(input_tensor)\n",
    "    x = layers.MaxPooling1D(pool_size=3, strides=2, padding='same')(x)\n",
    "\n",
    "    # Residual Blocks\n",
    "    x = residual_block_1d(x, 64, 1)\n",
    "    x = residual_block_1d(x, 128, 2)\n",
    "    x = residual_block_1d(x, 256, 2)\n",
    "    x = residual_block_1d(x, 512, 2)\n",
    "\n",
    "    # Global Average Pooling\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "    # Fully Connected layer\n",
    "    x = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Create model\n",
    "    model = models.Model(inputs=input_tensor, outputs=x, name='resnet18_1d')\n",
    "\n",
    "    return model\n",
    "\n",
    "def residual_block_1d(input_tensor, filters, strides):\n",
    "    shortcut = input_tensor\n",
    "\n",
    "    # First convolution layer\n",
    "    x = layers.Conv1D(filters, kernel_size=3, strides=strides, padding='same', activation='relu')(input_tensor)\n",
    "\n",
    "    # Second convolution layer\n",
    "    x = layers.Conv1D(filters, kernel_size=3, padding='same', activation='relu')(x)\n",
    "\n",
    "    # Shortcut connection\n",
    "    if strides != 1 or input_tensor.shape[-1] != filters:\n",
    "        shortcut = layers.Conv1D(filters, kernel_size=1, strides=strides, padding='valid', activation='relu')(input_tensor)\n",
    "\n",
    "    # Add shortcut to main path\n",
    "    x = layers.add([x, shortcut])\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "692f303d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet18_1d\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, 1000, 12)]           0         []                            \n",
      "                                                                                                  \n",
      " conv1d_29 (Conv1D)          (None, 500, 64)              5440      ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling1d_7 (MaxPoolin  (None, 250, 64)              0         ['conv1d_29[0][0]']           \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " conv1d_30 (Conv1D)          (None, 250, 64)              12352     ['max_pooling1d_7[0][0]']     \n",
      "                                                                                                  \n",
      " conv1d_31 (Conv1D)          (None, 250, 64)              12352     ['conv1d_30[0][0]']           \n",
      "                                                                                                  \n",
      " add_8 (Add)                 (None, 250, 64)              0         ['conv1d_31[0][0]',           \n",
      "                                                                     'max_pooling1d_7[0][0]']     \n",
      "                                                                                                  \n",
      " conv1d_32 (Conv1D)          (None, 125, 128)             24704     ['add_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_33 (Conv1D)          (None, 125, 128)             49280     ['conv1d_32[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_34 (Conv1D)          (None, 125, 128)             8320      ['add_8[0][0]']               \n",
      "                                                                                                  \n",
      " add_9 (Add)                 (None, 125, 128)             0         ['conv1d_33[0][0]',           \n",
      "                                                                     'conv1d_34[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_35 (Conv1D)          (None, 63, 256)              98560     ['add_9[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_36 (Conv1D)          (None, 63, 256)              196864    ['conv1d_35[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_37 (Conv1D)          (None, 63, 256)              33024     ['add_9[0][0]']               \n",
      "                                                                                                  \n",
      " add_10 (Add)                (None, 63, 256)              0         ['conv1d_36[0][0]',           \n",
      "                                                                     'conv1d_37[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_38 (Conv1D)          (None, 32, 512)              393728    ['add_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_39 (Conv1D)          (None, 32, 512)              786944    ['conv1d_38[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_40 (Conv1D)          (None, 32, 512)              131584    ['add_10[0][0]']              \n",
      "                                                                                                  \n",
      " add_11 (Add)                (None, 32, 512)              0         ['conv1d_39[0][0]',           \n",
      "                                                                     'conv1d_40[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_2  (None, 512)                  0         ['add_11[0][0]']              \n",
      "  (GlobalAveragePooling1D)                                                                        \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 5)                    2565      ['global_average_pooling1d_2[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1755717 (6.70 MB)\n",
      "Trainable params: 1755717 (6.70 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "input_shape_1d = (1000, 12)  # Adjust input size based on your data\n",
    "num_classes = 5  # Adjust based on your classification task\n",
    "\n",
    "resnet18_1d_model = build_1d_resnet18(input_shape_1d, num_classes)\n",
    "\n",
    "# Display model summary\n",
    "resnet18_1d_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1f486aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "resnet18_1d_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "646bc89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0ae837bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3278/3278 [==============================] - 79s 24ms/step - loss: 0.0910 - accuracy: 0.9694 - val_loss: 0.3142 - val_accuracy: 0.9295\n",
      "Epoch 2/100\n",
      "3278/3278 [==============================] - 78s 24ms/step - loss: 0.0851 - accuracy: 0.9723 - val_loss: 0.3629 - val_accuracy: 0.9169\n",
      "Epoch 3/100\n",
      "3278/3278 [==============================] - 75s 23ms/step - loss: 0.0893 - accuracy: 0.9714 - val_loss: 0.3480 - val_accuracy: 0.9260\n",
      "Epoch 4/100\n",
      "3278/3278 [==============================] - 73s 22ms/step - loss: 0.0791 - accuracy: 0.9730 - val_loss: 0.3641 - val_accuracy: 0.9335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x39f05a250>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet18_1d_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split = 0.2,\n",
    "    epochs=100,\n",
    "    batch_size = 8,\n",
    "    callbacks = early_stopping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "078a588a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 3s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = resnet18_1d_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "681ea2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 3s 13ms/step - loss: 0.3376 - accuracy: 0.9210\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3375917971134186, 0.9210301637649536]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet18_1d_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650e659d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d7606b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "k_folds = 5\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4adefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store the results\n",
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "# Iterate over the folds\n",
    "for train_index, test_index in skf.split(X, Y[:,0]):\n",
    "    X_train, X_val = X[train_index], X[test_index]\n",
    "    y_train, y_val = Y[train_index], Y[test_index]\n",
    "    \n",
    "    resnet18_1d_model.compile(\n",
    "        optimizer=optimizer, \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    history = resnet18_1d_model.fit(\n",
    "        X_train, y_train, \n",
    "        epochs=10, \n",
    "        batch_size=32, \n",
    "        validation_data=(X_val, y_val), \n",
    "        verbose=0)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    loss, accuracy = resnet18_1d_model.evaluate(X_val, y_val, verbose=0)\n",
    "\n",
    "    # Store the results\n",
    "    losses.append(loss)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Print the average results over all folds\n",
    "print(f'Average Loss: {np.mean(losses)}')\n",
    "print(f'Average Accuracy: {np.mean(accuracies)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ed95d0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32772, 5)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1d6b2e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[16244])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21f5786b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(y)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398c188d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
