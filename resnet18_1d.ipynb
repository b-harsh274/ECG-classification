{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75659fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wfdb\n",
    "import ast\n",
    "\n",
    "def load_raw_data(df, sampling_rate):\n",
    "    if sampling_rate == 100:\n",
    "        data = [wfdb.rdsamp(f) for f in df.filename_lr]\n",
    "    else:\n",
    "        data = [wfdb.rdsamp(f) for f in df.filename_hr]\n",
    "    data = np.array([signal for signal, meta in data])\n",
    "    return data\n",
    "\n",
    "sampling_rate=100\n",
    "\n",
    "# load and convert annotation data\n",
    "df = pd.read_csv('ptbxl_database.csv', index_col='ecg_id')\n",
    "df.scp_codes = df.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# Load raw signal data\n",
    "Signals = load_raw_data(df, sampling_rate)\n",
    "\n",
    "# Load scp_statements.csv for diagnostic aggregation\n",
    "agg_df = pd.read_csv('scp_statements.csv', index_col=0)\n",
    "agg_df = agg_df[agg_df.diagnostic == 1]\n",
    "\n",
    "def aggregate_diagnostic(y_dic):\n",
    "    tmp = []\n",
    "    for key in y_dic.keys():\n",
    "        if key in agg_df.index:\n",
    "            tmp.append(agg_df.loc[key].diagnostic_class)\n",
    "    return list(set(tmp))\n",
    "\n",
    "# Apply diagnostic superclass\n",
    "df.reset_index(inplace=True)\n",
    "Labels = df.scp_codes.apply(aggregate_diagnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7f0395",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=[]\n",
    "x=[]\n",
    "\n",
    "for i in range(len(Labels)):\n",
    "    if Labels[i] == list(['CD']):\n",
    "        y.append('CD')\n",
    "        x.append(Signals[i,:,0])\n",
    "    if Labels[i] == list(['HYP']):\n",
    "        y.append('HYP')\n",
    "        x.append(Signals[i,:,0])\n",
    "    if Labels[i] == list(['NORM']):\n",
    "        y.append('NORM')\n",
    "        x.append(Signals[i,:,0])\n",
    "    if Labels[i] == list(['STTC']):\n",
    "        y.append('STTC')\n",
    "        x.append(Signals[i,:,0])\n",
    "    if Labels[i] == list(['MI']):\n",
    "        y.append('MI')\n",
    "        x.append(Signals[i,:,0])\n",
    "\n",
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279f121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_signals = []\n",
    "augmented_labels = []\n",
    "\n",
    "\n",
    "for label in ['CD', 'HYP', 'MI', 'STTC']:\n",
    "    target_indices = np.where(y == label)[0]\n",
    "    augmentation_factor = (np.count_nonzero(y == 'NORM')  // np.count_nonzero(y == label)) -1\n",
    "    \n",
    "    for index in target_indices:\n",
    "        repeated_signal = np.tile(x[index], (augmentation_factor, 1))\n",
    "        noisy_signal = repeated_signal + 0.01 * np.random.randn(*repeated_signal.shape)\n",
    "        repeated_signal_2d = repeated_signal.reshape(-1, repeated_signal.shape[-1])\n",
    "        augmented_signals.append(noisy_signal)\n",
    "        augmented_labels.extend([y[index]] * augmentation_factor)\n",
    "    \n",
    "X = np.concatenate([x] + augmented_signals)\n",
    "Y = np.concatenate([y, np.array(augmented_labels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4641fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "Y_encoded = label_encoder.fit_transform(Y)\n",
    "\n",
    "Y_onehot = to_categorical(Y_encoded, num_classes=5)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y_onehot, test_size=0.2, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88310b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_1d_resnet18(input_shape, num_classes):\n",
    "    input_tensor = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Initial Convolution\n",
    "    x = layers.Conv1D(64, kernel_size=7, strides=2, padding='same', activation='relu')(input_tensor)\n",
    "    x = layers.MaxPooling1D(pool_size=3, strides=2, padding='same')(x)\n",
    "\n",
    "    # Residual Blocks\n",
    "    x = residual_block_1d(x, 64, 1)\n",
    "    x = residual_block_1d(x, 128, 2)\n",
    "    x = residual_block_1d(x, 256, 2)\n",
    "    x = residual_block_1d(x, 512, 2)\n",
    "\n",
    "    # Global Average Pooling\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "    # Fully Connected layer\n",
    "    x = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Create model\n",
    "    model = models.Model(inputs=input_tensor, outputs=x, name='resnet18_1d')\n",
    "\n",
    "    return model\n",
    "\n",
    "def residual_block_1d(input_tensor, filters, strides):\n",
    "    shortcut = input_tensor\n",
    "\n",
    "    # First convolution layer\n",
    "    x = layers.Conv1D(filters, kernel_size=3, strides=strides, padding='same', activation='relu')(input_tensor)\n",
    "\n",
    "    # Second convolution layer\n",
    "    x = layers.Conv1D(filters, kernel_size=3, padding='same', activation='relu')(x)\n",
    "\n",
    "    # Shortcut connection if needed\n",
    "    if strides != 1 or input_tensor.shape[-1] != filters:\n",
    "        shortcut = layers.Conv1D(filters, kernel_size=1, strides=strides, padding='valid', activation='relu')(input_tensor)\n",
    "\n",
    "    # Add shortcut to main path\n",
    "    x = layers.add([x, shortcut])\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7a3a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1000, 12)\n",
    "num_classes = 5  \n",
    "\n",
    "resnet18_1d_model = build_1d_resnet18(input_shape, num_classes)\n",
    "\n",
    "resnet18_1d_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa6adeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "resnet18_1d_model.compile(\n",
    "    optimizer=optimizer, \n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23b5188",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaaf961",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18_1d_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split = 0.2,\n",
    "    epochs=100,\n",
    "    batch_size = 8,\n",
    "    callbacks = early_stopping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9521ea45",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18_1d_model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
