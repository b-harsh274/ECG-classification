{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f42207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wfdb\n",
    "import ast\n",
    "\n",
    "def load_raw_data(df, sampling_rate):\n",
    "    if sampling_rate == 100:\n",
    "        data = [wfdb.rdsamp(f) for f in df.filename_lr]\n",
    "    else:\n",
    "        data = [wfdb.rdsamp(f) for f in df.filename_hr]\n",
    "    data = np.array([signal for signal, meta in data])\n",
    "    return data\n",
    "\n",
    "sampling_rate=100\n",
    "\n",
    "# load and convert annotation data\n",
    "df = pd.read_csv('ptbxl_database.csv', index_col='ecg_id')\n",
    "df.scp_codes = df.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# Load raw signal data\n",
    "Signals = load_raw_data(df, sampling_rate)\n",
    "\n",
    "# Load scp_statements.csv for diagnostic aggregation\n",
    "agg_df = pd.read_csv('scp_statements.csv', index_col=0)\n",
    "agg_df = agg_df[agg_df.diagnostic == 1]\n",
    "\n",
    "def aggregate_diagnostic(y_dic):\n",
    "    tmp = []\n",
    "    for key in y_dic.keys():\n",
    "        if key in agg_df.index:\n",
    "            tmp.append(agg_df.loc[key].diagnostic_class)\n",
    "    return list(set(tmp))\n",
    "\n",
    "# Apply diagnostic superclass\n",
    "df.reset_index(inplace=True)\n",
    "Labels = df.scp_codes.apply(aggregate_diagnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de2d2b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=[]\n",
    "x=[]\n",
    "for i in range(len(Labels)):\n",
    "    if Labels[i] == list(['CD']):\n",
    "        y.append('CD')\n",
    "        x.append(Signals[i,:,0])\n",
    "    if Labels[i] == list(['HYP']):\n",
    "        y.append('HYP')\n",
    "        x.append(Signals[i,:,0])\n",
    "    if Labels[i] == list(['NORM']):\n",
    "        y.append('NORM')\n",
    "        x.append(Signals[i,:,0])\n",
    "    if Labels[i] == list(['STTC']):\n",
    "        y.append('STTC')\n",
    "        x.append(Signals[i,:,0])\n",
    "    if Labels[i] == list(['MI']):\n",
    "        y.append('MI')\n",
    "        x.append(Signals[i,:,0])\n",
    "\n",
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30363124",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_signals = []\n",
    "augmented_labels = []\n",
    "\n",
    "\n",
    "for label in ['CD', 'HYP', 'MI', 'STTC']:\n",
    "    target_indices = np.where(y == label)[0]\n",
    "    augmentation_factor = (np.count_nonzero(y == 'NORM')  // np.count_nonzero(y == label)) -1\n",
    "    \n",
    "    for index in target_indices:\n",
    "        repeated_signal = np.tile(x[index], (augmentation_factor, 1))\n",
    "        noisy_signal = repeated_signal + 0.01 * np.random.randn(*repeated_signal.shape)\n",
    "        repeated_signal_2d = repeated_signal.reshape(-1, repeated_signal.shape[-1])\n",
    "        augmented_signals.append(noisy_signal)\n",
    "        augmented_labels.extend([y[index]] * augmentation_factor)\n",
    "    \n",
    "X = np.concatenate([x] + augmented_signals)\n",
    "Y = np.concatenate([y, np.array(augmented_labels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3cf3e950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "Y_encoded = label_encoder.fit_transform(Y)\n",
    "\n",
    "Y_onehot = to_categorical(Y_encoded, num_classes=5)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y_onehot, test_size=0.2, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0c68b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_1d_resnet18(input_shape, num_classes):\n",
    "    input_tensor = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Initial Convolution\n",
    "    x = layers.Conv1D(64, kernel_size=7, strides=2, padding='same', activation='relu')(input_tensor)\n",
    "    x = layers.MaxPooling1D(pool_size=3, strides=2, padding='same')(x)\n",
    "\n",
    "    # Residual Blocks\n",
    "    x = residual_block_1d(x, 64, 1)\n",
    "    x = residual_block_1d(x, 128, 2)\n",
    "    x = residual_block_1d(x, 256, 2)\n",
    "    x = residual_block_1d(x, 512, 2)\n",
    "\n",
    "    # Global Average Pooling\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "    # Fully Connected layer\n",
    "    x = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Create model\n",
    "    model = models.Model(inputs=input_tensor, outputs=x, name='resnet18_1d')\n",
    "\n",
    "    return model\n",
    "\n",
    "def residual_block_1d(input_tensor, filters, strides):\n",
    "    shortcut = input_tensor\n",
    "\n",
    "    # First convolution layer\n",
    "    x = layers.Conv1D(filters, kernel_size=3, strides=strides, padding='same', activation='relu')(input_tensor)\n",
    "\n",
    "    # Second convolution layer\n",
    "    x = layers.Conv1D(filters, kernel_size=3, padding='same', activation='relu')(x)\n",
    "\n",
    "    # Shortcut connection if needed\n",
    "    if strides != 1 or input_tensor.shape[-1] != filters:\n",
    "        shortcut = layers.Conv1D(filters, kernel_size=1, strides=strides, padding='valid', activation='relu')(input_tensor)\n",
    "\n",
    "    # Add shortcut to main path\n",
    "    x = layers.add([x, shortcut])\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8637bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-23 21:54:28.254639: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2024-01-23 21:54:28.254711: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-01-23 21:54:28.254721: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-01-23 21:54:28.255325: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-01-23 21:54:28.255848: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet18_1d\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 1000, 12)]           0         []                            \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)             (None, 500, 64)              5440      ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1  (None, 250, 64)              0         ['conv1d[0][0]']              \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)           (None, 250, 64)              12352     ['max_pooling1d[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)           (None, 250, 64)              12352     ['conv1d_1[0][0]']            \n",
      "                                                                                                  \n",
      " add (Add)                   (None, 250, 64)              0         ['conv1d_2[0][0]',            \n",
      "                                                                     'max_pooling1d[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)           (None, 125, 128)             24704     ['add[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)           (None, 125, 128)             49280     ['conv1d_3[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)           (None, 125, 128)             8320      ['add[0][0]']                 \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, 125, 128)             0         ['conv1d_4[0][0]',            \n",
      "                                                                     'conv1d_5[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)           (None, 63, 256)              98560     ['add_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)           (None, 63, 256)              196864    ['conv1d_6[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)           (None, 63, 256)              33024     ['add_1[0][0]']               \n",
      "                                                                                                  \n",
      " add_2 (Add)                 (None, 63, 256)              0         ['conv1d_7[0][0]',            \n",
      "                                                                     'conv1d_8[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)           (None, 32, 512)              393728    ['add_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)          (None, 32, 512)              786944    ['conv1d_9[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)          (None, 32, 512)              131584    ['add_2[0][0]']               \n",
      "                                                                                                  \n",
      " add_3 (Add)                 (None, 32, 512)              0         ['conv1d_10[0][0]',           \n",
      "                                                                     'conv1d_11[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d (  (None, 512)                  0         ['add_3[0][0]']               \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 5)                    2565      ['global_average_pooling1d[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1755717 (6.70 MB)\n",
      "Trainable params: 1755717 (6.70 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (1000, 12)\n",
    "num_classes = 5  \n",
    "\n",
    "resnet18_1d_model = build_1d_resnet18(input_shape, num_classes)\n",
    "\n",
    "resnet18_1d_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e98577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "resnet18_1d_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f9782325",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "k_folds = 5\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "550034d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/harshbalgude/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/harshbalgude/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/harshbalgude/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/harshbalgude/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/harshbalgude/miniconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/harshbalgude/miniconda3/lib/python3.11/site-packages/keras/src/engine/input_spec.py\", line 253, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'resnet18_1d' (type Functional).\n    \n    Input 0 of layer \"conv1d\" is incompatible with the layer: expected min_ndim=3, found ndim=2. Full shape received: (None, 1000)\n    \n    Call arguments received by layer 'resnet18_1d' (type Functional):\n      • inputs=tf.Tensor(shape=(None, 1000), dtype=float32)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 16\u001b[0m\n\u001b[1;32m     10\u001b[0m resnet18_1d_model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     11\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptimizer, \n\u001b[1;32m     12\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     13\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m history \u001b[38;5;241m=\u001b[39m resnet18_1d_model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     17\u001b[0m     x_train, y_train, \n\u001b[1;32m     18\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, \n\u001b[1;32m     19\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, \n\u001b[1;32m     20\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39m(x_val, y_val), \n\u001b[1;32m     21\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the validation set\u001b[39;00m\n\u001b[1;32m     24\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m resnet18_1d_model\u001b[38;5;241m.\u001b[39mevaluate(x_val, y_val, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/k6/2sv64y2n2x30zc_wwpgjvy4h0000gn/T/__autograph_generated_file2ylvdwdx.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/harshbalgude/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/harshbalgude/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/harshbalgude/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/harshbalgude/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/harshbalgude/miniconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/harshbalgude/miniconda3/lib/python3.11/site-packages/keras/src/engine/input_spec.py\", line 253, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'resnet18_1d' (type Functional).\n    \n    Input 0 of layer \"conv1d\" is incompatible with the layer: expected min_ndim=3, found ndim=2. Full shape received: (None, 1000)\n    \n    Call arguments received by layer 'resnet18_1d' (type Functional):\n      • inputs=tf.Tensor(shape=(None, 1000), dtype=float32)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store the results\n",
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "# Iterate over the folds\n",
    "for train_index, test_index in skf.split(X_train, Y_train[:,0]):\n",
    "    x_train, x_val = X_train[train_index], X_train[test_index]\n",
    "    y_train, y_val = Y_train[train_index], Y_train[test_index]\n",
    "    \n",
    "    resnet18_1d_model.compile(\n",
    "        optimizer=optimizer, \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    history = resnet18_1d_model.fit(\n",
    "        x_train, y_train, \n",
    "        epochs=10, \n",
    "        batch_size=32, \n",
    "        validation_data=(x_val, y_val), \n",
    "        verbose=0)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    loss, accuracy = resnet18_1d_model.evaluate(x_val, y_val, verbose=0)\n",
    "\n",
    "    # Store the results\n",
    "    losses.append(loss)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Print the average results over all folds\n",
    "print(f'Average Loss: {np.mean(losses)}')\n",
    "print(f'Average Accuracy: {np.mean(accuracies)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0f8f9944",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/harshbalgude/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/harshbalgude/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/harshbalgude/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/harshbalgude/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/harshbalgude/miniconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/harshbalgude/miniconda3/lib/python3.11/site-packages/keras/src/engine/input_spec.py\", line 280, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'resnet18_1d' (type Functional).\n    \n    Input 0 of layer \"conv1d\" is incompatible with the layer: expected axis -1 of input shape to have value 12, but received input with shape (None, 1000, 1)\n    \n    Call arguments received by layer 'resnet18_1d' (type Functional):\n      • inputs=tf.Tensor(shape=(None, 1000, 1), dtype=float32)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 17\u001b[0m\n\u001b[1;32m     11\u001b[0m resnet18_1d_model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     12\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m     13\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     14\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m history \u001b[38;5;241m=\u001b[39m resnet18_1d_model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     18\u001b[0m     x_train, y_train,\n\u001b[1;32m     19\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     20\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m     21\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39m(x_val, y_val),\n\u001b[1;32m     22\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the validation set\u001b[39;00m\n\u001b[1;32m     25\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m resnet18_1d_model\u001b[38;5;241m.\u001b[39mevaluate(x_val, y_val, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/k6/2sv64y2n2x30zc_wwpgjvy4h0000gn/T/__autograph_generated_file2ylvdwdx.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/harshbalgude/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/harshbalgude/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/harshbalgude/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/harshbalgude/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/harshbalgude/miniconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/harshbalgude/miniconda3/lib/python3.11/site-packages/keras/src/engine/input_spec.py\", line 280, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'resnet18_1d' (type Functional).\n    \n    Input 0 of layer \"conv1d\" is incompatible with the layer: expected axis -1 of input shape to have value 12, but received input with shape (None, 1000, 1)\n    \n    Call arguments received by layer 'resnet18_1d' (type Functional):\n      • inputs=tf.Tensor(shape=(None, 1000, 1), dtype=float32)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the folds\n",
    "for train_index, test_index in skf.split(X_train, Y_train[:, 0]):\n",
    "    x_train, x_val = X_train[train_index], X_train[test_index]\n",
    "    y_train, y_val = Y_train[train_index], Y_train[test_index]\n",
    "\n",
    "    # Ensure x_train and x_val have the correct shape\n",
    "    # The shape should be (batch_size, time_steps, features)\n",
    "    x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "    x_val = x_val.reshape((x_val.shape[0], x_val.shape[1], 1))\n",
    "\n",
    "    resnet18_1d_model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = resnet18_1d_model.fit(\n",
    "        x_train, y_train,\n",
    "        epochs=10,\n",
    "        batch_size=32,\n",
    "        validation_data=(x_val, y_val),\n",
    "        verbose=0)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    loss, accuracy = resnet18_1d_model.evaluate(x_val, y_val, verbose=0)\n",
    "\n",
    "    # Store the results\n",
    "    losses.append(loss)\n",
    "    accuracies.append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a2c954",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
